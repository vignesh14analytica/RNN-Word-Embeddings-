{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMBD rating.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYd687tpcRmP6SCgJ9ecGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vignesh14analytica/RNN-Word-Embeddings-/blob/master/IMBD_rating.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XieLjXhye9rc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Sequential\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Pc221V-fVox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY5Iz18to1Bi",
        "colab_type": "text"
      },
      "source": [
        "**Importing IMDB dataset from Keras datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3nYi0FTfaMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "imbd, info = tfds.load(\"imdb_reviews\", with_info=True, as_supervised=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3pLmiCepGre",
        "colab_type": "text"
      },
      "source": [
        "**Organising data into sentences and labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk-YiUCqftw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data = imbd['test'], imbd['test']\n",
        "\n",
        "train_sentences = []\n",
        "train_labels = []\n",
        "\n",
        "test_sentences = []\n",
        "test_labels = []\n",
        "\n",
        "for s,l in train_data:\n",
        "  train_sentences.append(s.numpy().decode('utf8'))\n",
        "  train_labels.append(l.numpy())\n",
        "\n",
        "for s,l in test_data:\n",
        "  test_sentences.append(s.numpy().decode('utf8'))\n",
        "  test_labels.append(l.numpy())\n",
        "\n",
        "training_labels = np.array(train_labels)\n",
        "testing_labels = np.array(test_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QekJta0rIFI",
        "colab_type": "text"
      },
      "source": [
        "**Setting up tokenizer, sequencing and Padding data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsIoG03vhV1W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_len = 120\n",
        "trunc_type = 'post'\n",
        "oov_tok = '<OOV>'\n",
        "\n",
        "tokenizer = Tokenizer(num_words= vocab_size, oov_token= oov_tok)\n",
        "tokenizer.fit_on_texts(train_sentences)\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(train_sentences)\n",
        "padded = pad_sequences(sequences= sequences, maxlen= max_len, truncating= trunc_type)\n",
        "\n",
        "test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
        "test_padded = pad_sequences(sequences= test_sequences, maxlen = max_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z975YTVzrX0M",
        "colab_type": "text"
      },
      "source": [
        "**Reversing word index to decode padded sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QlDFSZklEKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "30e1f225-dd8e-4779-d900-e80d1d9742b3"
      },
      "source": [
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i, '?') for i in text])\n",
        "\n",
        "print(decode_review(padded[3]))\n",
        "print(train_sentences[3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "poor shirley <OOV> tries hard to lend some <OOV> to this <OOV> gag inducing feel good movie but she's <OOV> by the run away sentimentality of a film that's not the least bit grounded in reality br br this was directed by curtis <OOV> did he have a <OOV> since we last heard from him <OOV> can do effective drama sprinkled with comedy as <OOV> by wonder boys so i don't know what happened to him here this is the kind of movie that doesn't want to accept that life is messy and <OOV> and that neat <OOV> endings however implausible they might be might make for a nice closing shot but come across as utterly phony if the people\n",
            "Poor Shirley MacLaine tries hard to lend some gravitas to this mawkish, gag-inducing \"feel-good\" movie, but she's trampled by the run-away sentimentality of a film that's not the least bit grounded in reality.<br /><br />This was directed by Curtis Hanson? Did he have a lobotomy since we last heard from him? Hanson can do effective drama sprinkled with comedy, as evidenced by \"Wonder Boys.\" So I don't know what happened to him here. This is the kind of movie that doesn't want to accept that life is messy and fussy, and that neat, tidy endings (however implausible they might be) might make for a nice closing shot, but come across as utterly phony if the people watching the film have been through anything remotely like what the characters in the film go through.<br /><br />My wife and I made a game of calling out the plot points before they occurred -- e.g. \"the old man's going to teach her to read and then drop dead.\" Bingo! This is one of those movies where the characters give little speeches summarizing their emotional problems, making you wonder why they still have emotional problems if they're that aware of what's causing them. Toni Collette (a fine actress, by the way, and one of my favorites if not given a lot to work with here), gives a speech early on about why she buys so many shoes and never wears them, spelling out in flashing neon the film's awkward connecting motif. At that moment, I knew what I was in for, and the film was a downward spiral from there.<br /><br />Grade: C-\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4cehCsGryys",
        "colab_type": "text"
      },
      "source": [
        "**Defining model and compiling with Loss function and Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ep_42V4lxuK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "95a212b2-5eda-411f-fed8-acede6d0ab02"
      },
      "source": [
        "model = Sequential([tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length = max_len),\n",
        "                    tf.keras.layers.Flatten(),\n",
        "                    tf.keras.layers.Dense(6, activation= 'relu'),\n",
        "                    tf.keras.layers.Dense(1, activation = 'sigmoid')])\n",
        "\n",
        "model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 120, 16)           160000    \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1920)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 6)                 11526     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 171,533\n",
            "Trainable params: 171,533\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6-HPDOkr9O8",
        "colab_type": "text"
      },
      "source": [
        "**Training the model for 10 epochs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAzB2k77nrQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "18158f60-854b-43f2-ebfe-da2446387084"
      },
      "source": [
        "num_epochs = 10\n",
        "model.fit(padded, training_labels, epochs = num_epochs, validation_data = (test_padded, testing_labels))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4817 - accuracy: 0.7461 - val_loss: 0.2828 - val_accuracy: 0.8838\n",
            "Epoch 2/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2270 - accuracy: 0.9123 - val_loss: 0.2644 - val_accuracy: 0.8881\n",
            "Epoch 3/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0899 - accuracy: 0.9765 - val_loss: 0.2903 - val_accuracy: 0.8898\n",
            "Epoch 4/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0229 - accuracy: 0.9970 - val_loss: 0.3365 - val_accuracy: 0.8885\n",
            "Epoch 5/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0072 - accuracy: 0.9994 - val_loss: 0.3639 - val_accuracy: 0.8906\n",
            "Epoch 6/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.3995 - val_accuracy: 0.8902\n",
            "Epoch 7/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 9.7221e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.8904\n",
            "Epoch 8/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 4.8744e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.8906\n",
            "Epoch 9/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 2.9109e-04 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.8906\n",
            "Epoch 10/10\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 1.7058e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.8903\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1f2ffde9b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hZH66WVp1hc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be84c193-525d-41af-c7ce-f55e9adcedb6"
      },
      "source": [
        "e = model.layers[0]\n",
        "weights = e.get_weights()[0]\n",
        "print(weights.shape) # shape: (vocab_size, embedding_dim)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdP1bwPpsYzn",
        "colab_type": "text"
      },
      "source": [
        "**Creating the embedding vector and Metadata file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXqlqha6ocbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, vocab_size):\n",
        "  word = reverse_word_index[word_num]\n",
        "  embeddings = weights[word_num]\n",
        "  out_m.write(word + \"\\n\")\n",
        "  out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9We-XBcseqB",
        "colab_type": "text"
      },
      "source": [
        "**Download the files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOM2nippp6Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEWYvbixq2qZ",
        "colab_type": "text"
      },
      "source": [
        "The word embeddings can be visualized with http://projector.tensorflow.org/"
      ]
    }
  ]
}